{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da96d2e9-17aa-4dc9-88a2-0fb65d4e1ad8",
   "metadata": {},
   "source": [
    "# Material compute demo agent\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adde229",
   "metadata": {},
   "source": [
    "\n",
    "## ç›®å½•ä¸æ­¥éª¤æŒ‡å—\n",
    "**è¯¥ notebook ä»…ä¾›å±•ç¤ºï¼Œå¦‚éœ€è¿è¡Œè¯·è®¿é—® github ä»“åº“ https://github.com/dptech-corp/material-compute-agent**\n",
    "\n",
    "æœ¬ Notebook å±•ç¤ºäº†ä¸€ä¸ªåˆ›æ–°çš„ææ–™è®¡ç®—ä»£ç†ç³»ç»Ÿï¼Œå®ƒåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å’Œ CAMEL å¤šä»£ç†æ¡†æ¶è‡ªåŠ¨åŒ–æ‰§è¡Œææ–™ç§‘å­¦ä¸­çš„è®¡ç®—ä»»åŠ¡ã€‚ç³»ç»Ÿæ¨¡æ‹Ÿäº†çœŸå®ç ”ç©¶å›¢é˜Ÿçš„åä½œè¿‡ç¨‹ï¼ŒåŒ…æ‹¬ä»æ–‡çŒ®ä¸­æå–ä¿¡æ¯ã€ç”Ÿæˆè®¡ç®—è¾“å…¥æ–‡ä»¶ã€æ‰§è¡Œè®¡ç®—ã€åˆ†æç»“æœå¹¶ç”ŸæˆæŠ¥å‘Šã€‚\n",
    "\n",
    "è¯¥ç³»ç»Ÿç‰¹åˆ«é€‚ç”¨äºé«˜é€šé‡ææ–™ç­›é€‰å’Œè®¡ç®—ææ–™ç§‘å­¦ç ”ç©¶ï¼Œèƒ½å¤Ÿæ˜¾è‘—æé«˜ææ–™å‘ç°å’Œä¼˜åŒ–çš„æ•ˆç‡ã€‚é€šè¿‡é›†æˆ Bohrium è®¡ç®—å¹³å°å’Œ VASP è®¡ç®—è½¯ä»¶ï¼Œç³»ç»Ÿå¯ä»¥æ‰§è¡Œä»å¯†åº¦æ³›å‡½ç†è®ºï¼ˆDFTï¼‰è®¡ç®—åˆ°çƒ­åŠ›å­¦æ€§è´¨åˆ†æçš„å„ç§ä»»åŠ¡ã€‚\n",
    "\n",
    "æœ¬æ¼”ç¤ºç‰¹åˆ«å…³æ³¨é’™é’›çŸ¿æ°§åŒ–ç‰©ææ–™ï¼ˆå¦‚ Sr5Ca3Fe8O24ï¼‰çš„è®¡ç®—æ¨¡æ‹Ÿï¼Œè¿™ç±»ææ–™åœ¨çƒ­åŒ–å­¦èƒ½é‡å­˜å‚¨ï¼ˆTCESï¼‰ç­‰é¢†åŸŸå…·æœ‰é‡è¦åº”ç”¨å‰æ™¯ã€‚\n",
    "\n",
    "1. **ç¯å¢ƒé…ç½®**\n",
    "   - å®‰è£…ä¾èµ–åŒ… (`%pip install -e .`)\n",
    "   - ä¸‹è½½å¹¶é…ç½® MP æ•°æ®é›†\n",
    "   - è®¾ç½® API å¯†é’¥ (Bohrium, OpenAI/Azure, DeepSeek)\n",
    "\n",
    "2. **ç³»ç»Ÿåˆå§‹åŒ–**\n",
    "   - å¯¼å…¥å¿…è¦çš„åº“å’Œå·¥å…·\n",
    "   - åˆ›å»ºæ¨¡å‹å®ä¾‹\n",
    "   - é…ç½®ä»£ç†è§’è‰²å’Œå·¥å…·\n",
    "\n",
    "3. **ä»»åŠ¡æ‰§è¡Œ**\n",
    "   - å¯åŠ¨ MCP æœåŠ¡ (`python vasp_mcp.py`)\n",
    "   - è¿æ¥åˆ° MCP æœåŠ¡å™¨\n",
    "   - åˆ›å»ºå¹¶é…ç½®å·¥ä½œæµç¨‹\n",
    "   - æäº¤è®¡ç®—ä»»åŠ¡\n",
    "\n",
    "4. **è¾“å…¥ç¤ºä¾‹**\n",
    "   - æ–‡ç« è·¯å¾„: test.pdf\n",
    "   - ææ–™ä½“ç³»: Sr5Ca3Fe8O24\n",
    "   - å‚æ•°ä¿®æ”¹: INCAR çš„ NELM = 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a033b9b5-8b3a-478f-a86d-6ae853aa1a12",
   "metadata": {},
   "source": [
    "## é…ç½®ç¯å¢ƒ\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9179b02",
   "metadata": {},
   "source": [
    "### å®‰è£…ä¾èµ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b50e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5faadb-9e05-4fa6-8a03-2b7548ba389e",
   "metadata": {},
   "source": [
    "### é…ç½®æœ¬åœ°mpæ•°æ®é›†ï¼Œç”¨äºæŸ¥è¯¢æ¨¡æ¿\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7c5380-451a-4377-a6e2-a1863fd22643",
   "metadata": {
    "jupyter": {
     "output_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!wget https://openfiles.mlops.dp.tech/projects/lp/6583cfd69e8f402898b60830889d242d/mp_materials_cif.zip\n",
    "\n",
    "!unzip -q mp_materials_cif.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa01822f",
   "metadata": {},
   "source": [
    "### å¼•å…¥ä¾èµ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa779386-c020-4315-9669-38513cb14bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from camel.toolkits.mcp_toolkit import MCPToolkit, MCPClient\n",
    "from camel.models import ModelFactory\n",
    "from camel.types import ModelPlatformType, ModelType\n",
    "from camel.agents import ChatAgent\n",
    "from vasp_function import read_vasp_pdf,write_vasp_report,analyze_vasprun_all,search_poscar_template,write_poscar,check_vasp_input,write_vasp_config,generate_vasp_config\n",
    "import warnings\n",
    "from utils import edit_job_json\n",
    "from camel.messages.base import BaseMessage\n",
    "\n",
    "from dp_camel.dp_workforce import DPWorkforce\n",
    "from camel.tasks.task import Task\n",
    "from camel.toolkits import (\n",
    "    HumanToolkit\n",
    ")\n",
    "from camel.toolkits import FunctionTool\n",
    "from camel.types import ModelPlatformType, ModelType\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cdf873-caa7-4fc4-b5b0-857bd3cc1283",
   "metadata": {},
   "source": [
    "### é…ç½®APIå’Œè¿è¡Œç¯å¢ƒé•œåƒ\n",
    "\n",
    "1. å¡«å…¥é¡¹ç›®ï¼Œé•œåƒåœ°å€ï¼ŒDP access keyï¼ŒOPENAI api\n",
    "2. å°†notebook ipåŠ å…¥lvmeng\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "809dbf17-609f-49a6-afd7-c6afc6a0ea38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start install bohrctl\n",
      "âœ… æˆåŠŸæ›´æ–° job.json\n",
      "é¡¹ç›®ç¼–å·: 21128\n",
      "é•œåƒåœ°å€: registry.dp.tech/dptech/vasp:5.4.4\n"
     ]
    }
   ],
   "source": [
    "# é…ç½® bohrium access key\n",
    "!echo 'export ACCESS_KEY=YOUR-BOHRIUM-KEY' >> ~/.bashrc #DP access key\n",
    "!source ~/.bashrc\n",
    "print(\"start install bohrctl\")\n",
    "\n",
    "%%bash\n",
    "\n",
    "# æ£€æµ‹ç³»ç»Ÿç±»å‹\n",
    "OS=$(uname)\n",
    "\n",
    "if [[ \"$OS\" == \"Linux\" ]]; then\n",
    "    echo \"ğŸŒ± æ­£åœ¨å®‰è£…é€‚ç”¨äº Linux çš„ bohr CLI...\"\n",
    "    bash -c \"$(curl -fsSL https://dp-public.oss-cn-beijing.aliyuncs.com/bohrctl/1.0.0/install_bohr_linux_curl.sh)\"\n",
    "elif [[ \"$OS\" == \"Darwin\" ]]; then\n",
    "    echo \"ğŸ æ­£åœ¨å®‰è£…é€‚ç”¨äº macOS çš„ bohr CLI...\"\n",
    "    bash -c \"$(curl -fsSL https://dp-public.oss-cn-beijing.aliyuncs.com/bohrctl/1.0.0/install_bohr_mac_curl.sh)\"\n",
    "else\n",
    "    echo \"âŒ ä¸æ”¯æŒçš„æ“ä½œç³»ç»Ÿ: $OS\"\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "os.environ[\"PATH\"] += \":~/.bohrium\"\n",
    "print(\"finish install bohrctl\")\n",
    "\n",
    "# é…ç½®OpenAI key\n",
    "os.environ[\"AZURE_OPENAI_BASE_URL\"] = \"YOUR-OPENAI-URL\" #OPENAI api\n",
    "print(\"start install bohrctl\")\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"YOUR-OPENAI-API-KEY\" #OPENAI api\n",
    "os.environ[\"AZURE_API_VERSION\"] = \"2024-08-01-preview\"#OPENAI api\n",
    "os.environ[\"AZURE_DEPLOYMENT_NAME\"] = \"gpt-4o\"\n",
    "\n",
    "#é…ç½®DeepSeek key\n",
    "os.environ[\"DEEP_SEEK_BASE_URL\"] = \"YOUR-DEEPSEEK-URL\" #DeepSeek api\n",
    "os.environ[\"DEEP_SEEK_API_KEY\"] = \"YOUR-DEEPSEEK-API-KEY\"#DeepSeek api\n",
    "os.environ[\"DEEP_SEEK_MODEL_NAME\"] = \"YOUR-DEEPSEEK-MODEL-NAME\" #DeepSeek api\n",
    "\n",
    "\n",
    "#åŠ å…¥æœ¬åœ°æ•°æ®é›†ä½ç½®\n",
    "os.environ[\"MP_ROOT_DIR\"] = \"mp_materials_cif\"# æœ¬åœ°æ•°æ®åº“ä½ç½®\n",
    "\n",
    "#å®šä¹‰æäº¤Vaspæ‰€éœ€è¦çš„job.jsonæ–‡ä»¶\n",
    "config = edit_job_json(\n",
    "    project_id=21128,  # \n",
    "    image_address=\"registry.dp.tech/dptech/vasp:5.4.4\",  # ä½¿ç”¨å®Œæ•´çš„é•œåƒåœ°å€\n",
    "    output_file=\"job.json\"\n",
    ")\n",
    "\n",
    "# os.environ['HTTP_PROXY'] = 'http://claude.op.xdptech.com:8118'\n",
    "# os.environ['HTTPS_PROXY'] = 'http://claude.op.xdptech.com:8118'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e6049b9-342c-4259-be91-d9901126dc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºåŸºç¡€æ¨¡å‹ï¼Œé€‰æ‹© AZURE å¹³å°å’Œ gpt-4o æ¨¡å‹\n",
    "model = ModelFactory.create(\n",
    "    model_platform=ModelPlatformType.AZURE,\n",
    "    model_type=ModelType.GPT_4O,\n",
    "    model_config_dict={\"temperature\": 0.1},\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da94574d-2fb6-426f-814d-4793f0946d2b",
   "metadata": {},
   "source": [
    "## åŸºç¡€prompt\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22d1ca2c-f5f6-4417-86cc-b54c004f959e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#å®šä¹‰æ•´ä½“ä»»åŠ¡ä¸ä¸åŒçš„è§’è‰²ï¼Œè¿™é‡Œéœ€è¦æè¿°çš„æ›´è¯¦ç»†ä¸€äº›ã€‚\n",
    "task_prompt = '''\n",
    "**ä»»åŠ¡ç›®æ ‡**ï¼šåšå£«ç”Ÿç”Ÿæˆå¯¹åº”ä½“ç³»çš„VASPè®¡ç®—é…ç½®ï¼Œå·¥ç¨‹å¸ˆæäº¤ä»»åŠ¡/ç›‘å¬ä»»åŠ¡ï¼Œæ”¶åˆ°ç»“æœåäº¤ç»™å†™æŠ¥å‘Šåšå£«è¾“å‡ºæŠ¥å‘Šï¼Œä»»åŠ¡ç»“æŸã€‚\n",
    "**å·¥ä½œæµç¨‹**ï¼š\n",
    "\n",
    "1. åšå£«ç”Ÿï¼š\n",
    "    ä½ éœ€è¦ä¸€æ­¥ä¸€æ­¥å¬ä»ä»»åŠ¡æŒ‡ç¤ºï¼Œé€æ­¥å®Œæˆä»»åŠ¡ï¼Œå¹¶åœ¨æ¯ä¸€æ­¥å®Œæˆåç»™å‡ºåé¦ˆä¸ä»»åŠ¡å®Œæˆæƒ…å†µ\n",
    "    - å‘äººç±»æé—®ï¼Œè·å–è®ºæ–‡è·¯å¾„ä¸è®¡ç®—çš„ä½“ç³»ï¼Œè°ƒç”¨read_vasp_pdfå·¥å…·ï¼Œè·å–è®ºæ–‡å†…å®¹ï¼Œè¿™ä¸€æ­¥ä¸éœ€è¦ä»»ä½•å›å¤ã€‚\n",
    "    - ä¹‹åï¼Œå…ˆè°ƒç”¨search_poscar_templateå·¥å…·ï¼Œç”ŸæˆPOSCARæ¨¡æ¿ï¼Œ\n",
    "    å¯¹POSCARæ¨¡æ¿è¿›è¡ŒåŸå­æ›¿æ¢(ä¸å†éœ€è¦search_poscar_template)ï¼Œç¡®ä¿ç»“æ„ä¸­çš„æ‰€æœ‰åŸå­ç§ç±»ã€æ•°é‡å’Œåˆ†å¸ƒéƒ½ä¸¥æ ¼ç¬¦åˆè¾“å…¥åŒ–å­¦å¼äººç±»å¸Œæœ›å¤ç°çš„åŒ–å­¦å¼ã€‚ä¹‹åä»¥\n",
    "    \"\"\"\n",
    "    åŸå­æ›¿æ¢åPOSCARæ–‡ä»¶å†…å®¹ï¼Œ\n",
    "    è¯·é—®ä½ æœ‰ä»€ä¹ˆä¿®æ”¹æ„è§ï¼Ÿ\n",
    "    \"\"\"\n",
    "    çš„å½¢å¼å‘äººç±»æé—®\n",
    "    å¹¶å‘äººç±»æé—®ä¿®æ”¹æ„è§ï¼Œç¡®è®¤åè¿›è¡Œä¸‹ä¸€æ­¥ã€‚\n",
    "    - è°ƒç”¨write_poscarå·¥å…·ï¼Œä½ éœ€è¦å°†ï¼ˆåŸå­æ›¿æ¢åçš„ï¼Œå®Œå…¨ç¬¦åˆPOSCARæ ¼å¼çš„strè¾“å…¥åˆ°å‡½æ•°ä¸­ï¼‰ï¼Œå°†POSCARæ–‡ä»¶å†…å®¹å†™å…¥æ–‡ä»¶ã€‚\n",
    "    - æ ¹æ®POSCARæ–‡ä»¶å†…å®¹å’Œæ–‡ä»¶æ ¼å¼ï¼Œç”Ÿæˆå¯¹åº”å®éªŒçš„XX.VTçš„æ–‡ä»¶å†…å®¹ï¼Œè°ƒç”¨write_vasp_configå·¥å…·ï¼Œç”ŸæˆVASPé…ç½®æ–‡ä»¶ã€‚\n",
    "    - ä½¿ç”¨check_vasp_inputå·¥å…·ï¼Œæ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœå­˜åœ¨ï¼Œåˆ™ç»§ç»­ï¼Œå¦åˆ™é‡æ–°ç”Ÿæˆå¯¹åº”çš„æ–‡ä»¶\n",
    "    - æ£€æŸ¥åå°†calcdirè¿”å›ç»™å·¥ç¨‹å¸ˆï¼Œcalcdiræ˜¯æ–‡ä»¶è·¯å¾„ï¼Œå¯ä»¥ç”¨åŒ–åˆç‰©åç§°å‘½åã€‚\n",
    "\n",
    "2. å·¥ç¨‹å¸ˆï¼š\n",
    "    - ä»åšå£«ç”Ÿæ¥æ”¶calcdir\n",
    "    - å…ˆå‘æˆ‘å±•ç¤ºè®¡ç®—é…ç½®ï¼Œä½¿ç”¨show_vasp_configå·¥å…·ï¼Œå…·ä½“è¿”å›INCARæ–‡ä»¶å†…å®¹å’Œè¯·é—®æ‚¨æœ‰ä»€ä¹ˆä¿®æ”¹æ„è§\n",
    "    - å¹¶è¯¢é—®äººç±»æ˜¯å¦éœ€è¦é‡å†™ï¼Œå¦‚æœéœ€è¦é‡å†™ï¼Œåˆ™é‡å†™å¹¶å±•ç¤ºï¼Œç›´åˆ°äººç±»è¿”å›OKï¼ŒéªŒè¯é€šè¿‡åï¼Œæäº¤VASPè®¡ç®—\n",
    "    - æ”¶åˆ°ä»»åŠ¡æäº¤æˆåŠŸåï¼Œå¼€å§‹ç›‘å¬ä»»åŠ¡ç»“æœï¼Œè¿”å›xml_path\n",
    "    - æ”¶åˆ°xml_pathåï¼Œé€šçŸ¥å†™æŠ¥å‘Šåšå£«ç”Ÿ\n",
    "\n",
    "3. å†™æŠ¥å‘Šåšå£«ç”Ÿï¼š\n",
    "    - æ¥æ”¶xml_path\n",
    "    - ä½¿ç”¨analyze_vasprun_allå·¥å…·ï¼Œåˆ†æVASPè®¡ç®—ç»“æœï¼Œ\n",
    "    - å¯¹è¿™ä¸ªç»“æœè¿›è¡Œä¸€å®šåˆ†æ,å¹¶å†™å…¥æŠ¥å‘Šï¼Œå®ŒæˆæŠ¥å‘Šåï¼Œä½¿ç”¨write_vasp_reportå·¥å…·ï¼Œå°†æŠ¥å‘Šå…·ä½“å†…å®¹å†™å…¥æ–‡ä»¶\n",
    "    - æ³¨æ„ï¼ŒæŠ¥å‘Šé‡Œé¢éœ€è¦åŒ…å«æ­¤æ¬¡è®¡ç®—çš„å…·ä½“åˆ†æã€‚\n",
    "\n",
    "æ³¨æ„åˆ†è§£å®Œä»»åŠ¡åï¼Œéœ€è¦å‘äººç±»ç¡®è®¤ï¼Œäººç±»ç¡®è®¤åï¼Œæ‰èƒ½å¼€å§‹æ‰§è¡Œä»»åŠ¡ã€‚\n",
    "'''\n",
    "\n",
    "#è¯»æ–‡çŒ®åšå£«ç”Ÿprompt\n",
    "phd_prompt = \"\"\"\n",
    "<role_definition>\n",
    "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é‡å­åŒ–å­¦åšå£«ç”Ÿï¼Œå…·æœ‰ä»¥ä¸‹ç‰¹ç‚¹ï¼š\n",
    "1. ç²¾é€šVASPè®¡ç®—å’Œæ™¶ä½“ç»“æ„åˆ†æ\n",
    "2. å¯¹æ–‡çŒ®æœ‰æå¼ºçš„ç†è§£èƒ½åŠ›\n",
    "3. å·¥ä½œä¸¥è°¨ï¼Œæ³¨é‡ç»†èŠ‚\n",
    "4. ä¸¥æ ¼æŒ‰ç…§è§„èŒƒè¾“å‡ºæ ¼å¼\n",
    "5. ç†è§£å¹¶ä½¿ç”¨å·¥å…·\n",
    "6. é‡åˆ°ç–‘é—®æ—¶ä¸»åŠ¨å‘äººç±»æé—®\n",
    "<role_definition>\n",
    "\"\"\"\n",
    "\n",
    "#å†™æŠ¥å‘Šåšå£«ç”Ÿ\n",
    "output_prompt = \"\"\"\n",
    "<role_definition>\n",
    "ä½ æ˜¯ä¸€ä¸ªææ–™æ¨¡æ‹Ÿåˆ†æä¸“å®¶ï¼Œæ”¶åˆ°xml_pathåï¼Œä½¿ç”¨analyze_vasprun_allå·¥å…·ï¼Œåˆ†æVASPè®¡ç®—ç»“æœ\n",
    "æ ¹æ®è®¡ç®—ç»“æœç”Ÿæˆä¸€ä»½æ ‡å‡†åŒ–çš„è®¡ç®—æŠ¥å‘Šï¼š\n",
    "\n",
    "æŠ¥å‘Šåº”åŒ…æ‹¬ï¼š\n",
    "- ç¨‹åºä¸å¹³å°ä¿¡æ¯\n",
    "- INCAR è®¾ç½®æ‘˜è¦\n",
    "- K ç‚¹ä¿¡æ¯ï¼ˆæ˜¯å¦è‡ªåŠ¨ç”Ÿæˆï¼‰\n",
    "- ç»“æ„æ˜¯å¦å­˜åœ¨ï¼Œè‹¥ç¼ºå¤±è¯·è¯´æ˜\n",
    "- æ˜¯å¦æœ‰åŠ›ä¿¡æ¯ï¼ŒåŠ›æ˜¯å¦ä¸ºé›¶\n",
    "- è‹¥å­˜åœ¨é”™è¯¯æˆ–ç¼ºå¤±ä¿¡æ¯ï¼Œä¹Ÿè¯·å¦‚å®å†™å…¥\n",
    "è¯·ä½¿ç”¨æ­£å¼ã€ä¸“ä¸šçš„è¯­æ°”å®Œæˆè¯¥æŠ¥å‘Šã€‚\n",
    "è¯·ä½ å°†è®¡ç®—æŠ¥å‘Šçš„ç»“æœçš„åˆ†æå†™åˆ°experiment_report.txté‡Œé¢\n",
    "<role_definition>\n",
    "\"\"\"\n",
    "\n",
    "# é¢å¤–çš„ä»»åŠ¡è¦æ±‚\n",
    "additional_info = \"\"\"\n",
    "**äº¤äº’è§„åˆ™**ï¼š\n",
    "1. åšå£«ç”Ÿå¿…é¡»ä¸¥æ ¼æŒ‰ç…§è§„èŒƒè¾“å‡ºæ ¼å¼\n",
    "2. æœ€ååšå£«ç”Ÿè¿è¡ŒæˆåŠŸåï¼Œå°†calcdirå‘Šè¯‰å·¥ç¨‹å¸ˆï¼Œäº¤ç»™å·¥ç¨‹å¸ˆè¿è¡ŒVASPè®¡ç®—ï¼Œå¹¶ç›‘å¬ä»»åŠ¡ç»“æœ,è¿”å›xml_pathã€‚\n",
    "3. å†™å®éªŒæŠ¥å‘Šåšå£«ç”Ÿè·å–xml_pathï¼Œå¹¶è¿è¡Œanalyze_vasprun_allå·¥å…·ï¼Œå¹¶å†™å®éªŒæŠ¥å‘Šã€‚\n",
    "\n",
    "**è´¨é‡è¦æ±‚**ï¼š\n",
    "1. æ‰€æœ‰å‚æ•°å¿…é¡»æ¥è‡ªæ–‡çŒ®\n",
    "\n",
    "**æ³¨æ„**ï¼š\n",
    "1. åšå£«ç”Ÿå¿…é¡»ä¸¥æ ¼æŒ‰ç…§è§„èŒƒè¾“å‡ºæ ¼å¼\n",
    "2. åšå£«ç”Ÿéœ€è¦ç¡®è®¤è‡ªæˆ‘æ£€æŸ¥\n",
    "3. æ‰€æœ‰äººåœ¨é‡åˆ°é—®é¢˜æ—¶ï¼Œå…ˆå‘äººç±»å¯»æ±‚æ„è§ã€‚\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176c5e65-e50a-4008-bb66-66ccf1e30146",
   "metadata": {},
   "source": [
    "## å®šä¹‰è§’è‰²ä¸å·¥å…·\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b78595a-1ef7-45b8-851b-7695973f424c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ä»¥è¿™ç§å½¢å¼å®šä¹‰å¯æ‰§è¡Œå·¥å…·\n",
    "\n",
    "humantoolkit = HumanToolkit()\n",
    "\n",
    "\n",
    "VASPtools: list[FunctionTool] = [\n",
    "    FunctionTool(func) for func in [write_vasp_config,analyze_vasprun_all,write_vasp_report,read_vasp_pdf]\n",
    "]\n",
    "\n",
    "POSCARtools: list[FunctionTool] = [\n",
    "    FunctionTool(func) for func in [search_poscar_template,write_poscar,check_vasp_input]\n",
    "]\n",
    "\n",
    "phd_agent = ChatAgent(\n",
    "    system_message=BaseMessage.make_assistant_message(\n",
    "        role_name=\"ç²¾é€šé‡å­åŒ–å­¦çš„åšå£«ç”Ÿ\",\n",
    "        content=phd_prompt,\n",
    "    ),\n",
    "    model=model,\n",
    "    output_language=\"zh-CN\",\n",
    "    tools=[*humantoolkit.get_tools(),*POSCARtools,*VASPtools]\n",
    ")\n",
    "\n",
    "phd_agent_write = ChatAgent(\n",
    "    system_message=BaseMessage.make_assistant_message(\n",
    "        role_name=\"ä¸“ä¸šè´Ÿè´£å†™æŠ¥å‘Šçš„åšå£«ç”Ÿ\",\n",
    "        content=output_prompt,\n",
    "    ),\n",
    "    model=model,\n",
    "    tools=[*VASPtools,*humantoolkit.get_tools()],\n",
    "    output_language=\"zh-CN\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf43ce2",
   "metadata": {},
   "source": [
    "åœ¨ç»ˆç«¯è¿è¡Œä»¥ä¸‹å‘½ä»¤,å¯åŠ¨mcpæœåŠ¡\n",
    "```bash\n",
    "python vasp_mcp.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ed20696-ddae-46ac-be25-fe44eeb2d4dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start connect to mcp server\n",
      "connected to mcp server\n",
      "2025-04-25 20:46:59,762 - camel.models.model_manager - ERROR - Error processing with model: <camel.models.azure_openai_model.AzureOpenAIModel object at 0x136fb40b0>\n",
      "2025-04-25 20:46:59,763 - camel.agents.chat_agent - ERROR - An error occurred while running model gpt-4o, index: 0\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/lhappy/miniconda3/envs/lhappy/lib/python3.12/site-packages/httpx/_transports/default.py\", line 101, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/Users/lhappy/miniconda3/envs/lhappy/lib/python3.12/site-packages/httpx/_transports/default.py\", line 250, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lhappy/miniconda3/envs/lhappy/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 207, in handle_request\n",
      "    raise UnsupportedProtocol(\n",
      "httpcore.UnsupportedProtocol: Request URL is missing an 'http://' or 'https://' protocol.\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/lhappy/miniconda3/envs/lhappy/lib/python3.12/site-packages/openai/_base_client.py\", line 989, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lhappy/miniconda3/envs/lhappy/lib/python3.12/site-packages/httpx/_client.py\", line 914, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lhappy/miniconda3/envs/lhappy/lib/python3.12/site-packages/httpx/_client.py\", line 942, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lhappy/miniconda3/envs/lhappy/lib/python3.12/site-packages/httpx/_client.py\", line 979, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lhappy/miniconda3/envs/lhappy/lib/python3.12/site-packages/httpx/_client.py\", line 1014, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lhappy/miniconda3/envs/lhappy/lib/python3.12/site-packages/httpx/_transports/default.py\", line 249, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/Users/lhappy/miniconda3/envs/lhappy/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/Users/lhappy/miniconda3/envs/lhappy/lib/python3.12/site-packages/httpx/_transports/default.py\", line 118, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.UnsupportedProtocol: Request URL is missing an 'http://' or 'https://' protocol.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/lhappy/miniconda3/envs/lhappy/lib/python3.12/site-packages/httpx/_transports/default.py\", line 101, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/Users/lhappy/miniconda3/envs/lhappy/lib/python3.12/site-packages/httpx/_transports/default.py\", line 250, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lhappy/miniconda3/envs/lhappy/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 207, in handle_request\n",
      "    raise UnsupportedProtocol(\n",
      "httpcore.UnsupportedProtocol: Request URL is missing an 'http://' or 'https://' protocol.\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/lhappy/miniconda3/envs/lhappy/lib/python3.12/site-packages/openai/_base_client.py\", line 989, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lhappy/miniconda3/envs/lhappy/lib/python3.12/site-packages/httpx/_client.py\", line 914, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lhappy/miniconda3/envs/lhappy/lib/python3.12/site-packages/httpx/_client.py\", line 942, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lhappy/miniconda3/envs/lhappy/lib/python3.12/site-packages/httpx/_client.py\", line 979, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lhappy/miniconda3/envs/lhappy/lib/python3.12/site-packages/httpx/_client.py\", line 1014, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lhappy/miniconda3/envs/lhappy/lib/python3.12/site-packages/httpx/_transports/default.py\", line 249, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/Users/lhappy/miniconda3/envs/lhappy/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/Users/lhappy/miniconda3/envs/lhappy/lib/python3.12/site-packages/httpx/_transports/default.py\", line 118, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.UnsupportedProtocol: Request URL is missing an 'http://' or 'https://' protocol.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/lhappy/miniconda3/envs/lhappy/lib/python3.12/site-packages/httpx/_transports/default.py\", line 101, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/Users/lhappy/miniconda3/envs/lhappy/lib/python3.12/site-packages/httpx/_transports/default.py\", line 250, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lhappy/miniconda3/envs/lhappy/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 207, in handle_request\n",
      "    raise UnsupportedProtocol(\n",
      "httpcore.UnsupportedProtocol: Request URL is missing an 'http://' or 'https://' protocol.\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/lhappy/miniconda3/envs/lhappy/lib/python3.12/site-packages/openai/_base_client.py\", line 989, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lhappy/miniconda3/envs/lhappy/lib/python3.12/site-packages/httpx/_client.py\", line 914, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lhappy/miniconda3/envs/lhappy/lib/python3.12/site-packages/httpx/_client.py\", line 942, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lhappy/miniconda3/envs/lhappy/lib/python3.12/site-packages/httpx/_client.py\", line 979, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lhappy/miniconda3/envs/lhappy/lib/python3.12/site-packages/httpx/_client.py\", line 1014, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lhappy/miniconda3/envs/lhappy/lib/python3.12/site-packages/httpx/_transports/default.py\", line 249, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/Users/lhappy/miniconda3/envs/lhappy/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/Users/lhappy/miniconda3/envs/lhappy/lib/python3.12/site-packages/httpx/_transports/default.py\", line 118, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.UnsupportedProtocol: Request URL is missing an 'http://' or 'https://' protocol.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/lhappy/miniconda3/envs/lhappy/lib/python3.12/site-packages/httpx/_transports/default.py\", line 101, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/Users/lhappy/miniconda3/envs/lhappy/lib/python3.12/site-packages/httpx/_transports/default.py\", line 250, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lhappy/miniconda3/envs/lhappy/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py\", line 207, in handle_request\n",
      "    raise UnsupportedProtocol(\n",
      "httpcore.UnsupportedProtocol: Request URL is missing an 'http://' or 'https://' protocol.\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/lhappy/miniconda3/envs/lhappy/lib/python3.12/site-packages/openai/_base_client.py\", line 989, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lhappy/miniconda3/envs/lhappy/lib/python3.12/site-packages/httpx/_client.py\", line 914, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lhappy/miniconda3/envs/lhappy/lib/python3.12/site-packages/httpx/_client.py\", line 942, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lhappy/miniconda3/envs/lhappy/lib/python3.12/site-packages/httpx/_client.py\", line 979, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lhappy/miniconda3/envs/lhappy/lib/python3.12/site-packages/httpx/_client.py\", line 1014, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lhappy/miniconda3/envs/lhappy/lib/python3.12/site-packages/httpx/_transports/default.py\", line 249, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/Users/lhappy/miniconda3/envs/lhappy/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/Users/lhappy/miniconda3/envs/lhappy/lib/python3.12/site-packages/httpx/_transports/default.py\", line 118, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.UnsupportedProtocol: Request URL is missing an 'http://' or 'https://' protocol.\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/lhappy/miniconda3/envs/lhappy/lib/python3.12/site-packages/camel/agents/chat_agent.py\", line 791, in _get_model_response\n",
      "    response = self.model_backend.run(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lhappy/miniconda3/envs/lhappy/lib/python3.12/site-packages/camel/models/model_manager.py\", line 226, in run\n",
      "    raise exc\n",
      "  File \"/Users/lhappy/miniconda3/envs/lhappy/lib/python3.12/site-packages/camel/models/model_manager.py\", line 216, in run\n",
      "    response = self.current_model.run(messages, response_format, tools)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lhappy/miniconda3/envs/lhappy/lib/python3.12/site-packages/camel/models/base_model.py\", line 50, in wrapped_run\n",
      "    return original_run(self, messages, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lhappy/miniconda3/envs/lhappy/lib/python3.12/site-packages/camel/models/base_model.py\", line 278, in run\n",
      "    return self._run(messages, response_format, tools)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lhappy/miniconda3/envs/lhappy/lib/python3.12/site-packages/camel/models/azure_openai_model.py\", line 153, in _run\n",
      "    return self._request_chat_completion(messages, tools)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lhappy/miniconda3/envs/lhappy/lib/python3.12/site-packages/camel/models/azure_openai_model.py\", line 194, in _request_chat_completion\n",
      "    return self._client.chat.completions.create(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lhappy/miniconda3/envs/lhappy/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lhappy/miniconda3/envs/lhappy/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 929, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/lhappy/miniconda3/envs/lhappy/lib/python3.12/site-packages/openai/_base_client.py\", line 1276, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lhappy/miniconda3/envs/lhappy/lib/python3.12/site-packages/openai/_base_client.py\", line 949, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/lhappy/miniconda3/envs/lhappy/lib/python3.12/site-packages/openai/_base_client.py\", line 1013, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lhappy/miniconda3/envs/lhappy/lib/python3.12/site-packages/openai/_base_client.py\", line 1091, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/lhappy/miniconda3/envs/lhappy/lib/python3.12/site-packages/openai/_base_client.py\", line 1013, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lhappy/miniconda3/envs/lhappy/lib/python3.12/site-packages/openai/_base_client.py\", line 1091, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/lhappy/miniconda3/envs/lhappy/lib/python3.12/site-packages/openai/_base_client.py\", line 1013, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lhappy/miniconda3/envs/lhappy/lib/python3.12/site-packages/openai/_base_client.py\", line 1091, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/lhappy/miniconda3/envs/lhappy/lib/python3.12/site-packages/openai/_base_client.py\", line 1023, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "Error during agent execution: Unable to process messages: the only provided model did not run successfully. Error: Connection error.\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import asyncio\n",
    "async def run_example():\n",
    "    mcp_client = MCPClient(\n",
    "        command_or_url=\"http://127.0.0.1:8000/sse\",\n",
    "    )\n",
    "    print(\"start connect to mcp server\")\n",
    "    await mcp_client.connect()\n",
    "    print(\"connected to mcp server\")\n",
    "    mcp_toolkit = MCPToolkit(servers=[mcp_client])\n",
    "    vasp_tools = mcp_toolkit.get_tools()\n",
    "    try:\n",
    "        engineer_agent = ChatAgent(\n",
    "            model=model,\n",
    "            system_message=\"ä½ æ˜¯ä¸€ä¸ªå·¥ç¨‹å¸ˆï¼Œè´Ÿè´£è¿è¡Œè„šæœ¬ï¼Œéœ€è¦å‘åšå£«ç”Ÿæ”¶åˆ°calcdirï¼Œèƒ½å¤Ÿè°ƒç”¨submit_vasp_jobå·¥å…·\",\n",
    "            tools=[*vasp_tools,*humantoolkit.get_tools()],\n",
    "            output_language=\"zh-CN\"\n",
    "        )\n",
    "        # Workforceç”¨äºMultiagentç³»ç»Ÿäº¤äº’ï¼ŒååŒå®Œæˆä»»åŠ¡ã€‚\n",
    "        workforce = DPWorkforce('VASPä»¿çœŸè®¡ç®—å›¢é˜Ÿ',\n",
    "                    coordinator_agent_kwargs={\"model\": model,\"output_language\":\"zh-CN\",\"tools\":[*humantoolkit.get_tools()]},\n",
    "                    task_agent_kwargs={\"model\": model,\"output_language\":\"zh-CN\",\"tools\":[*humantoolkit.get_tools()]},\n",
    "                    new_worker_agent_kwargs={\"model\": model,\"output_language\":\"zh-CN\",\"tools\":[*humantoolkit.get_tools()]}\n",
    "                )\n",
    "\n",
    "        workforce.add_single_agent_worker(\n",
    "            \"ç²¾é€šVASP/ä»¿çœŸè®¡ç®—çš„åšå£«ç”Ÿ\",\n",
    "            worker=phd_agent,\n",
    "        ).add_single_agent_worker(\n",
    "            \"è´Ÿè´£æäº¤ä»»åŠ¡çš„å·¥ç¨‹å¸ˆ\",\n",
    "            worker=engineer_agent\n",
    "        ).add_single_agent_worker(\n",
    "            \"è´Ÿè´£å†™å®éªŒæŠ¥å‘Šçš„åšå£«ç”Ÿ\",\n",
    "            worker=phd_agent_write)\n",
    "\n",
    "\n",
    "\n",
    "        human_task = Task(\n",
    "            content=task_prompt,\n",
    "            ional_info= additional_info,\n",
    "            id='0',\n",
    "        )\n",
    "\n",
    "        task = workforce.process_task(human_task)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during agent execution: {e}\")\n",
    "\n",
    "    finally:\n",
    "        await mcp_client.disconnect()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # asyncio.run(run_example()\n",
    "    await run_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fe2d08-0666-4a61-a5ea-09687fa8fd31",
   "metadata": {},
   "source": [
    "## æ ·ä¾‹è¾“å…¥\n",
    "\n",
    "1. æ–‡ç« æ˜¯test.pdf,æˆ‘æƒ³ç ”ç©¶Sr5Ca3Fe8O24ä½“ç³»çš„å®éªŒï¼ˆæä¾›æ–‡çŒ®è·¯å¾„ç”¨äºè¯»å–ä¸åŒçš„æ–‡çŒ®ï¼‰\n",
    "2. æˆ‘æƒ³æŠŠINCARçš„NELM = 200 ä¿®æ”¹ä¸º 2\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lhappy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
